{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5458f1",
   "metadata": {},
   "source": [
    "# Робота з текстом. spacy. NER\n",
    "\n",
    "- Використання можливостей бібліотеки spacy\n",
    "- Використати одну із моделей української мови для розмітки сутностей\n",
    "\n",
    "**NER (Named Entity Recognition) або Розпізнавання іменованих сутностей** — це завдання в області обробки природної мови (NLP), яке полягає у виявленні та класифікації ключових об'єктів у тексті.\n",
    "\n",
    "**Що робить NER?**\n",
    "\n",
    "**NER** визначає, які частини тексту є сутностями (entities), та класифікує їх за попередньо визначеними категоріями. Це можуть бути:\n",
    "\n",
    "- **LOC** (Location): Географічні місця (міста, країни, річки тощо).\n",
    "- **PERSON** (Person): Імена людей.\n",
    "- **ORG** (Organization): Організації (компанії, урядові установи, команди).\n",
    "- **DATE** (Date): Дати.\n",
    "- **TIME** (Time): Час.\n",
    "- **MONEY** (Money): Грошові суми.\n",
    "- **PERCENT** (Percentage): Відсотки.\n",
    "- **PRODUCT** (Product): Продукти (техніка, ліки тощо).\n",
    "- **GPE** (Geopolitical Entity): Політичні або адміністративні об'єкти.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "682a93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download uk_core_news_lg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e288d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Текст для аналізу\n",
    "text = \"15 грудня 2023 року в Парижі, Франція, Ілон Маск зустрівся з представниками Tesla та SpaceX. Було оголошено про фінансування в розмірі 1,5 мільярда доларів.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5430493",
   "metadata": {},
   "source": [
    "## Зробимо аналіз тексту з використанням україньскої моделі uk_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f390cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: Парижі, Категорія: LOC\n",
      "Текст: Франція, Категорія: LOC\n",
      "Текст: Ілон Маск, Категорія: PER\n",
      "Текст: Tesla, Категорія: ORG\n",
      "Текст: SpaceX., Категорія: ORG\n"
     ]
    }
   ],
   "source": [
    "# Завантажуємо українську модель\n",
    "nlp = spacy.load(\"uk_core_news_lg\")\n",
    "\n",
    "# Аналіз тексту\n",
    "doc = nlp(text)\n",
    "\n",
    "# Виводимо результати\n",
    "for ent in doc.ents:\n",
    "    print(f\"Текст: {ent.text}, Категорія: {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958e527",
   "metadata": {},
   "source": [
    "Нажаль ця модель не може розпізнати дати (DATE) та грошові одиниці (MONEY). Щож доведется щось робити. Як варіант додамо до NLP-пайплайну додатковий аналізатор на DATE та MONEY\n",
    "\n",
    "**NLP-пайплайн** — це послідовність етапів обробки тексту, яку застосовують для виконання завдань у галузі обробки природної мови (NLP). У контексті бібліотеки spaCy, пайплайн — це набір компонентів, кожен з яких виконує певну задачу, наприклад токенізацію, визначення частин мови, розпізнавання іменованих сутностей тощо.\n",
    "\n",
    "**Основні завдання NLP-пайплайну**\n",
    "1. Токенізація: Розбиття тексту на токени (слова, розділові знаки, символи тощо).\n",
    "2. Лематизація: Зведення слів до базової форми (наприклад, \"біг\" → \"бігти\").\n",
    "3. Частини мови (POS-теги): Визначення частини мови для кожного слова.\n",
    "4. NER (Named Entity Recognition): Розпізнавання і класифікація сутностей (імена, дати, місця, організації тощо).\n",
    "5. Dependency Parsing: Визначення граматичних зв’язків між словами.\n",
    "6. Кастомні компоненти: Додаткові етапи, наприклад, застосування регулярних виразів або специфічного аналізу тексту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17c5a0",
   "metadata": {},
   "source": [
    "## Зробимо аналіз тексту з використанням україньскої моделі uk_core_news_lg з додаваннм свого власного компоненту який буде знаходити DATE та MONEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af8de0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: 15 грудня 2023, Категорія: DATE\n",
      "Текст: Парижі, Категорія: LOC\n",
      "Текст: Франція, Категорія: LOC\n",
      "Текст: Ілон Маск, Категорія: PER\n",
      "Текст: Tesla, Категорія: ORG\n",
      "Текст: SpaceX., Категорія: ORG\n",
      "Текст: 1,5 мільярда доларів, Категорія: MONEY\n"
     ]
    }
   ],
   "source": [
    "# Це стандартний Python-модуль для роботи з регулярними виразами.\n",
    "import re\n",
    "\n",
    "# Це імпорт класу Language із бібліотеки spaCy. Ми використовуємо його для створення кастомного компонента NLP-пайплайну за допомогою декоратора @Language.component.\n",
    "from spacy.language import Language\n",
    "\n",
    "# Завантажуємо українську модель але на цей раз додамо підтримку категорій DATE та MONEY\n",
    "nlp2 = spacy.load(\"uk_core_news_lg\")\n",
    "\n",
    "# Кастомний компонент для регулярних виразів\n",
    "@Language.component(\"regex_ner\")\n",
    "def regex_ner_component(doc):\n",
    "    patterns = {\n",
    "        \"DATE\": r\"\\d{1,2} (січня|лютого|грудня) \\d{4}\",\n",
    "        \"MONEY\": r\"\\d+([.,]\\d+)? (мільярда|мільйона|тисяч) доларів\"\n",
    "    }\n",
    "    matches = []\n",
    "    for label, pattern in patterns.items():\n",
    "        for match in re.finditer(pattern, doc.text):\n",
    "            start, end = match.span()\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "            if span:\n",
    "                matches.append(span)\n",
    "\n",
    "    doc.ents = list(doc.ents) + matches  # Додаємо нові сутності до наявних\n",
    "    return doc\n",
    "\n",
    "# Реєструємо компонент у spaCy\n",
    "nlp2.add_pipe(\"regex_ner\", name=\"regex_ner\", last=True)\n",
    "\n",
    "# Аналіз тексту\n",
    "doc = nlp2(text)\n",
    "\n",
    "# Вивід розпізнаних сутностей\n",
    "for ent in doc.ents:\n",
    "    print(f\"Текст: {ent.text}, Категорія: {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data from the processed text\n",
    "entities = ['DATE', 'LOC', 'PER', 'ORG', 'MONEY']\n",
    "counts = [5, 3, 4, 2, 1]  # Example counts\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(entities, counts)\n",
    "plt.title('Frequency of Named Entities')\n",
    "plt.xlabel('Entity Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject_kernel",
   "language": "python",
   "name": "myproject_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
